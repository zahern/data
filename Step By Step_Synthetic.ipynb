{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a companion piece to all the code lines in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing: Installation of the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install metacountregressor --upgrade\n",
    "!pip install matplotlib --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing: Importing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metacountregressor.solution import ObjectiveFunction\n",
    "from metacountregressor.metaheuristics import (harmony_search,differential_evolution,simulated_annealing)         \n",
    "from metacountregressor import helperprocess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing: Loading in data (example syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"d_rp.csv\")\n",
    "y = df['Y']  # Frequency of crashes\n",
    "X = df.drop(columns=['Y']) # setup X based on data\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current notebook's directory\n",
    "notebook_directory = Path().resolve()\n",
    "\n",
    "# Set the working directory to the notebook's location\n",
    "os.chdir(notebook_directory)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing: Defining and Offset Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['Offset'] = X['LENGTH']*np.log1p(X['AADT']) #Modify Here for Desired Offset\n",
    "#X = X.drop(columns=['LENGTH', 'AADT'])  \n",
    "y_name ='FREQ'\n",
    "offset_name = 'Offset'\n",
    "group_name = None\n",
    "panel_name = None\n",
    "\n",
    "# grabbing the offset amount\n",
    "X['Offset'] = 1/5 #Modify Here for Desired Offset\n",
    "\n",
    "\n",
    "X = X.dropna(how='any')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customising the arguments for objective and metaheuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {'test_percentage': 0.3, 'complexity_level': 3, 'reg_penalty':0, 'MAX_TIME':6} #Objective args\n",
    "arguments_hs = {'_par': 0.3, '_hms': 20}\n",
    "arguments_sa = None #Note: Supply the relevant arguments, otherwise default arguments will be used\n",
    "arguments_de = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the objective function for the available metaheuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_solution = None\n",
    "obj_fun = ObjectiveFunction(X, y, **arguments)\n",
    "#perform harmony search\n",
    "results_hs = harmony_search(obj_fun, initial_solution, **arguments_hs)\n",
    "#perform differential evolution\n",
    "''' Commenting out as only one metaheuristic should be used at a time, feel free to test the others\n",
    "results_de = differential_evolution(obj_fun, initial_solution, **arguments_de)\n",
    "#perform simulated annealing\n",
    "results_sa = simulated_annealing(obj_fun, initial_solution, **arguments_sa)'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prespecifying an Intitial Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_fit_spec = {\n",
    "'fixed_terms': ['X1', 'X2'],\n",
    "'rdm_terms':  ['X3:uniform', 'X4:uniform', 'X5:normal'],\n",
    "'rdm_cor_terms': [],\n",
    "'grouped_terms': [],\n",
    "'hetro_in_means': [],\n",
    "'transformations': ['no', 'no', 'no', 'no', 'no'],\n",
    "'dispersion': 0\n",
    "}\n",
    "\n",
    "arguments['Manual_Fit'] = manual_fit_spec\n",
    "\n",
    "obj_fun = ObjectiveFunction(X, y, **arguments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hetrogeienity in the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"d_hm.csv\")\n",
    "y = df['Y']  # Frequency of crashes\n",
    "X = df.drop(columns=['Y']) # setup X based on data\n",
    "X.columns\n",
    "print(X.columns)\n",
    "\n",
    "manual_fit_spec = {\n",
    "'fixed_terms': ['const'],\n",
    "'rdm_terms':  [ 'X1:uniform'],\n",
    "'rdm_cor_terms': [],\n",
    "'grouped_terms': [],\n",
    "'hetro_in_means': ['X2:normal', 'Z1:normal','X3:normal'],\n",
    "'transformations': ['no', 'no', 'no', 'no', 'no', 'no'],\n",
    "'dispersion': 0\n",
    "}\n",
    "arguments = {'test_percentage': 0.2, 'complexity_level': 3, 'reg_penalty':0} #Objective args\n",
    "arguments['Manual_Fit'] = manual_fit_spec\n",
    "initial_solution = None\n",
    "obj_fun = ObjectiveFunction(X, y, **arguments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouped random paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/zahern/data/refs/heads/main/rural_int.csv\")\n",
    "y = df['crashes']  # Frequency of crashes\n",
    "\n",
    "df.drop(columns=[ 'year', 'orig_ID',\n",
    "                                    'jurisdiction', 'town', 'maint_region', 'weather_station', 'dummy_winter_2', 'month', 'inj.fat', 'PDO', 'zonal_ID', 'ln_AADT', 'ln_seg'], inplace=True)  # was dropped postcode\n",
    "\n",
    "           \n",
    "\n",
    "arguments_hs = {'_par': 0.3, '_hms': 20}\n",
    "arguments = {'test_percentage': 0.2, 'complexity_level': 5, 'reg_penalty':0} #Objective args\n",
    "# Step 2: Process Data\n",
    "model_terms = {\n",
    "    'Y': 'crashes',         # Dependent variable\n",
    "    'group': 'county',       # Grouping column (if any)\n",
    "    'panels': 'element_ID',      # Panel column (if any)\n",
    "    'Offset': None       # Offset column (if any)\n",
    "}\n",
    "\n",
    "\n",
    "X = df.drop(columns=['crashes']) # setup X based on data\n",
    "X.columns\n",
    "print(X.columns)\n",
    "\n",
    "manual_fit_spec = {\n",
    "'fixed_terms': ['const', 'DP10'],\n",
    "'rdm_terms':  [ 'DX32:normal'],\n",
    "'rdm_cor_terms': [],\n",
    "'group_rdm': ['DPO1:triangular'],\n",
    "'hetro_in_means': [],\n",
    "'transformations': ['no', 'no', 'no', 'no', 'no', 'no'],\n",
    "'dispersion': 0\n",
    "}\n",
    "arguments = {'test_percentage': 0.2, 'complexity_level': 6, 'reg_penalty':0, 'group':'county', 'panels':'element_ID'} #Objective args\n",
    "arguments['Manual_Fit'] = manual_fit_spec\n",
    "#initial_solution = None\n",
    "obj_fun = ObjectiveFunction(X, y, **arguments)\n",
    "initial_solution = None\n",
    "results_hs = harmony_search(obj_fun, initial_solution, **arguments_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constrained Search Versus Freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTRAINED SEARCH\n",
    "model_terms = {\n",
    "    'Y': 'Y',         # Replace 'FREQ' with the name of your dependent variable\n",
    "    'group': None,    # Replace 'group_column' with the name of your grouping column (or None if not used)\n",
    "    'panels': None,      # Replace 'panel_column' with the name of your panel column (or None if not used)\n",
    "    'Offset': None                # Replace None with the name of your offset column if not using one\n",
    "}\n",
    "variable_decisions = {\n",
    "'X1': {'levels': [0,1], 'transformations': ['no'], 'distributions': []},\n",
    "'X2': {'levels': [1, 2,5], 'transformations': ['no'], 'distributions': ['n', 't']},\n",
    "'X3':{'levels': [0, 2,5], 'transformations': ['no'], 'distributions': ['u', 'ln', 'tn']},\n",
    "'Z1': {'levels': [0,5], 'transformations': ['no'], 'distributions': ['u', 'ln', 'tn']},\n",
    "'Z2': {'levels': [0,1,5], 'transformations': ['no'], 'distributions': ['ln']}\n",
    "}\n",
    "\n",
    "a_des, X = helperprocess.set_up_analyst_constraints(X, model_terms, variable_decisions)\n",
    "\n",
    "arguments['decisions'] = a_des\n",
    "arguments['model_types'] = [[0]]\n",
    "arguments['instance'] = 'constrained' # GIVE NAME\n",
    "arguments['algorithm']='hs'\n",
    "arguments_unconstrained = arguments.copy()\n",
    "arguments_unconstrained['decisions'] = None\n",
    "arguments_unconstrained['instance'] = 'unconstrained'\n",
    "obj_fun = ObjectiveFunction(X, y, **arguments)\n",
    "results = harmony_search(obj_fun)\n",
    "helperprocess.results_printer(results, arguments['algorithm'], int(arguments['is_multi']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_fun = ObjectiveFunction(X, y, **arguments_unconstrained)\n",
    "results = harmony_search(obj_fun)\n",
    "helperprocess.results_printer(results, arguments_unconstrained['algorithm'], int(arguments_unconstrained['is_multi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
